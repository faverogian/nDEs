{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac60c9f-3cc4-4faa-ad1d-a60807b09bdf",
   "metadata": {},
   "source": [
    "# Prepare Weather Data\n",
    "The ODE model takes the data from a csv file in the format of daily averages of (date, temp, humidity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e17e34-d446-4960-a82e-24b5c3419ace",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543be75f-9ac2-4bd9-94ad-614579e7ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar 26 11:35:18 2024\n",
    "\n",
    "@author: Tanaka Akiyama\n",
    "\"\"\"\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate daily averages\n",
    "def calculate_daily_average(data):\n",
    "    # Number of hours in a day\n",
    "    hours_per_day = 24\n",
    "\n",
    "    # Reshape data to represent daily segments\n",
    "    data = data.reshape(-1, hours_per_day)\n",
    "\n",
    "    # Calculate daily averages\n",
    "    day_averages = np.nanmean(data, axis=1)\n",
    "    \n",
    "    return day_averages\n",
    "\n",
    "# Function to calculate bi-weekly averages\n",
    "def calculate_biweekly_averages(data):\n",
    "    # Number of hours in two weeks\n",
    "    hours_per_biweek = 24 * 14\n",
    "\n",
    "    # Determine the number of complete bi-weekly segments\n",
    "    num_biweeks = len(data) // hours_per_biweek\n",
    "\n",
    "    # Adjust the data to include only the necessary number of hours\n",
    "    data = data[:num_biweeks * hours_per_biweek]\n",
    "\n",
    "    # Reshape data to represent bi-weekly segments\n",
    "    data = data.reshape(-1, hours_per_biweek)\n",
    "\n",
    "    # Calculate bi-weekly averages\n",
    "    biweekly_averages = np.mean(data, axis=1)\n",
    "    \n",
    "    return biweekly_averages\n",
    "\n",
    "# Load NetCDF file\n",
    "def load_netcdf(file_path):\n",
    "    dataset = nc.Dataset(file_path)\n",
    "    return dataset\n",
    "\n",
    "    \n",
    "'''\n",
    "Combines multiple years of data into the same dataframe\n",
    "'''\n",
    "def combine_variables(file_paths, average='biweekly'):\n",
    "    temps = []\n",
    "    humidities = []\n",
    "    times = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        # Load NetCDF file\n",
    "        dataset = load_netcdf(file_path)\n",
    "\n",
    "        # Extract temperature and humidity data\n",
    "        temperature_kelvin = dataset.variables['t'][:, 0, 0]  # Assuming only one latitude and longitude point\n",
    "        humidity = dataset.variables['r'][:, 0, 0]  # Assuming only one latitude and longitude point\n",
    "        time = dataset.variables['time'][:]\n",
    "        \n",
    "        ''' Seems like scales and offsets are already applied?\n",
    "        # Extract scale and offset factors from attributes for temperature and humidity\n",
    "        temperature_scale = dataset.variables['t'].scale_factor\n",
    "        temperature_offset = dataset.variables['t'].add_offset\n",
    "        humidity_scale = dataset.variables['r'].scale_factor\n",
    "        humidity_offset = dataset.variables['r'].add_offset\n",
    "\n",
    "        # Apply scale and offset factors to temperature and humidity data and convert to celcius\n",
    "        temperature = (temperature_kelvin * temperature_scale) + temperature_offset - 273.15\n",
    "        humidity = (humidity * humidity_scale + humidity_offset)\n",
    "        '''\n",
    "\n",
    "        #temperature = temperature_kelvin - 273.15\n",
    "        temperature = temperature_kelvin\n",
    "\n",
    "        # Set missing values to NaN\n",
    "        temperature[temperature == -32767] = np.nan\n",
    "        humidity[humidity == -32767] = np.nan\n",
    "\n",
    "        # Calculate averages\n",
    "        if average=='biweekly':\n",
    "            temp_average = calculate_biweekly_averages(temperature)\n",
    "            humidity_average = calculate_biweekly_averages(humidity)\n",
    "            time_average = calculate_biweekly_averages(time)\n",
    "        else:\n",
    "            temp_average = calculate_daily_average(temperature)\n",
    "            humidity_average = calculate_daily_average(humidity)\n",
    "            time_average = calculate_daily_average(time)\n",
    "\n",
    "        temps.append(temp_average)\n",
    "        humidities.append(humidity_average)\n",
    "        times.append(time_average)\n",
    "\n",
    "        dataset.close()\n",
    "\n",
    "    all_temperature = np.concatenate(temps)\n",
    "    all_humidity = np.concatenate(humidities)\n",
    "    all_dates = np.concatenate(times)\n",
    "\n",
    "    # Convert numeric time values to datetime objects\n",
    "    all_dates = nc.num2date(all_dates, units=\"hours since 1900-01-01 00:00:00.0\", calendar=\"gregorian\")\n",
    "    \n",
    "    # Extract only the date portion from datetime objects\n",
    "    all_dates = [datetime(d.year, d.month, d.day) for d in all_dates]\n",
    "\n",
    "    return all_temperature, all_humidity, all_dates, \n",
    "    \n",
    "\n",
    "# print_netcdf_metadata(netcdf_file_path)\n",
    "file_paths = ['../../data/raw/weather/temp_relhum_2013.nc', '../../data/raw/weather/temp_relhum_2014.nc', \\\n",
    "                    '../../data/raw/weather/temp_relhum_2015.nc', '../../data/raw/weather/temp_relhum_2016.nc', \\\n",
    "             '../../data/raw/weather/temp_relhum_2017.nc', '../../data/raw/weather/2018.nc', \\\n",
    "             '../../data/raw/weather/temp_relhum_2019.nc', '../../data/raw/weather/2020.nc', \\\n",
    "             '../../data/raw/weather/2021.nc', '../../data/raw/weather/2022.nc']\n",
    "\n",
    "temps, humidities, dates = combine_variables(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b748a146-e861-408d-accb-ce99677ddd78",
   "metadata": {},
   "source": [
    "## Save data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655aa094-9dba-4fa0-9860-cd1f0bb839a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: ../../data/processed\\train_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Main function\n",
    "def save_to_csv(temps, humidities, dates, train_percent=0.93):\n",
    "    # Load NetCDF files for each year\n",
    "    datasets = [load_netcdf(file_path) for file_path in file_paths]\n",
    "    \n",
    "    # Create DataFrame with temperature, humidity, and index columns\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'temperature': temps,\n",
    "        'humidity': humidities\n",
    "    })\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_size = int(len(df) * train_percent)\n",
    "    #train_df = df.iloc[:train_size]\n",
    "    #test_df = df.iloc[train_size:]\n",
    "\n",
    "    # Save train and test DataFrames to CSV files\n",
    "    output_folder = '../../data/processed'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    train_output_file = os.path.join(output_folder, 'train_weather_data.csv')\n",
    "    #test_output_file = os.path.join(output_folder, 'test_weather_data.csv')\n",
    "    df.to_csv(train_output_file, index=False)\n",
    "    #test_df.to_csv(test_output_file, index=False)\n",
    "    print(\"Train data saved to:\", train_output_file)\n",
    "    #print(\"Test data saved to:\", test_output_file)\n",
    "\n",
    "save_to_csv(temps, humidities, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728d8a9-0562-426a-982d-5ff66e3d7635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
