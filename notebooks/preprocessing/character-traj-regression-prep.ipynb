{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Pipeline for Character Trajectories Dataset  \n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the code for importing the raw CharacterTrajectories dataset and preparing it for use with a torchcde, LSTM, and RNN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the data\n",
    "train_X, train_y = load_from_tsfile_to_dataframe('../../data/raw//char_traj/CharacterTrajectories_TRAIN.ts')\n",
    "test_X, test_y = load_from_tsfile_to_dataframe('../../data/raw/char_traj/CharacterTrajectories_TEST.ts')\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "train_X = train_X.to_numpy()\n",
    "test_X = test_X.to_numpy()\n",
    "\n",
    "# Concatenate the data to form a single dataset\n",
    "X = np.concatenate((train_X, test_X), axis=0)   # (batch, channel)\n",
    "y = np.concatenate((train_y, test_y), axis=0)\n",
    "\n",
    "# Change the labels to start from 0 and be integers\n",
    "classes = np.unique(y)\n",
    "y = np.array([np.where(classes == yi)[0][0] for yi in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad(channel, maxlen):\n",
    "    channel = torch.tensor(channel)\n",
    "    mean_value = torch.mean(channel)\n",
    "    out = torch.full((maxlen,), mean_value, dtype=channel.dtype)\n",
    "    out[:channel.size(0)] = channel\n",
    "    return out\n",
    "\n",
    "# Pad all data to same size with zeros. To be corrected for torchcde\n",
    "lengths = torch.tensor([len(Xi[0]) for Xi in X])\n",
    "maxlen = lengths.max()\n",
    "\n",
    "X = torch.stack([torch.stack([_pad(channel, maxlen) for channel in batch], dim=0) for batch in X], dim=0)\n",
    "X = X.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "mean = X.mean(dim=1, keepdim=True)\n",
    "std = X.std(dim=1, keepdim=True)\n",
    "X = (X - mean) / std\n",
    "\n",
    "# Replace near zero values with zero\n",
    "X[torch.abs(X) < 1e-5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmari\\AppData\\Local\\Temp\\ipykernel_3832\\3901171844.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  times = torch.tensor(times)\n"
     ]
    }
   ],
   "source": [
    "# Add time as a channel\n",
    "times = [np.linspace(0, lengths[i] - 1, lengths[i]) for i in range(len(X))]\n",
    "for i, time in enumerate(times):\n",
    "    padding = np.zeros(maxlen - len(time))\n",
    "    times[i] = np.concatenate((time, padding))\n",
    "\n",
    "times = torch.tensor(times)\n",
    "\n",
    "X = torch.cat((times.unsqueeze(-1), X), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(X, lengths):\n",
    "    '''\n",
    "    Create labels for the data. The data is the first\n",
    "    2/3 of each sequence and the labels are the last 1/3.\n",
    "    Sequences are padded with zeros to be the same length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.Tensor\n",
    "        The data of shape (batch, seq_length, channels).\n",
    "    lengths : torch.Tensor\n",
    "        The lengths of the sequences.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : torch.Tensor\n",
    "        The data of shape (batch, seq_length, channels).\n",
    "    labels : torch.Tensor\n",
    "        The labels of shape (batch, seq_length, channels).\n",
    "    '''\n",
    "    data = torch.zeros(X.size(0), X.size(1) * 2 // 3, X.size(2))\n",
    "    labels = torch.zeros(X.size(0), X.size(1) * 1 // 3 + 1, X.size(2))\n",
    "\n",
    "    for i in range(X.size(0)):\n",
    "        # Pad datapoint with zeros\n",
    "        datapoint = X[i, :lengths[i] * 2 // 3]\n",
    "        padding = torch.zeros(X.size(1) * 2 // 3 - len(datapoint), X.size(2))\n",
    "        datapoint = torch.cat((datapoint, padding))\n",
    "\n",
    "        # Pad label with zeros\n",
    "        label = X[i, lengths[i] * 2 // 3:lengths[i]]\n",
    "        padding = torch.zeros(X.size(1) * 1 // 3 - len(label) + 1, X.size(2))\n",
    "        label = torch.cat((label, padding))\n",
    "        \n",
    "        data[i] = datapoint\n",
    "        labels[i] = label\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "data, labels = create_labels(X, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a 80-20 train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Save the data\n",
    "path = '../../data/processed/CharacterTrajectories/regression/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "torch.save(X_train, os.path.join(path, 'X_train.pt'))\n",
    "torch.save(y_train, os.path.join(path, 'y_train.pt'))\n",
    "torch.save(X_test, os.path.join(path, 'X_test.pt'))\n",
    "torch.save(y_test, os.path.join(path, 'y_test.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2858, 120)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [2858, 120] at index 1 does not match the shape of the indexed tensor [2858, 182, 4] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Set the missing values to NaN\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     X[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m---> 27\u001b[0m \u001b[43minsert_random_missingness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36minsert_random_missingness\u001b[1;34m(X, y, missing_rate)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Set the missing values to NaN\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [2858, 120] at index 1 does not match the shape of the indexed tensor [2858, 182, 4] at index 1"
     ]
    }
   ],
   "source": [
    "def insert_random_missingness(X, y, missing_rate):\n",
    "    '''\n",
    "    Insert random missingness into the data.\n",
    "    Only the first 120 sequence elements will be affected (avg length of 120).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        The input data. Shape (n_samples, sequence_length, n_features)\n",
    "    y : np.array\n",
    "        The target data. Shape (n_samples,)\n",
    "    missing_rate : float\n",
    "        The rate of missingness to insert in sequences of the samples. \n",
    "        Each sample in X will have this proportion of its sequence (each feature)\n",
    "        set to NaN. \n",
    "    '''\n",
    "    n_samples, _, _ = X.shape\n",
    "\n",
    "    # Generate a mask of missingness \n",
    "    mask = np.random.rand(n_samples, 120) < missing_rate\n",
    "\n",
    "    print(mask.shape)\n",
    "\n",
    "    # Set the missing values to NaN\n",
    "    X[mask] = np.nan\n",
    "\n",
    "insert_random_missingness(X, y, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
