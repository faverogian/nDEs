Hyperparameters
log_dir: /logs
data_path: ../../data/processed/CharacterTrajectories/classification
missing_rate: 0.25
epochs: 100
lr: 0.001
batch_size: 32
input_channels: 5
hidden_channels: 32
output_channels: 20
hidden_layers: 3
method: rk4
step_size: 1


History
train_loss: [2.72835636138916, 2.160043478012085, 1.4728182554244995, 1.1121490001678467, 1.1585935354232788, 1.1229380369186401, 0.7101781368255615, 0.40550413727760315, 0.3748999834060669, 0.24521054327487946, 0.15401232242584229, 0.08556998521089554, 0.026703929528594017, 0.11224773526191711, 0.09703967720270157, 0.031038830056786537, 0.009713289327919483, 0.03308698162436485, 0.032226789742708206, 0.019053764641284943, 0.014702166430652142, 0.033757906407117844, 0.00671311654150486, 0.2593945562839508, 0.010873567312955856, 0.05142197012901306, 0.014308284036815166, 0.003783988766372204, 0.005482275038957596, 0.0069944411516189575, 0.0089036850258708, 0.03331020846962929, 0.0077784559689462185, 0.002561920089647174, 0.00894226972013712, 0.014864020980894566, 0.005970472004264593, 0.0028530315030366182, 0.011822191067039967, 0.0018641743808984756, 0.0032841693609952927, 0.0020365493837743998, 0.00364521611481905, 0.0017774830339476466, 0.0011826734989881516, 0.005753058474510908, 0.0093022296205163, 0.013079819269478321, 0.0018926610937342048, 0.0017997288377955556, 0.0013777980348095298, 0.0010127845453098416, 0.02085042931139469, 0.004140752833336592, 0.0019949544221162796, 0.0021557470317929983, 0.002806641161441803, 0.0018286952981725335, 0.004268142860382795, 0.0013314904645085335, 0.005100561771541834, 0.008509175851941109, 0.016433218494057655, 0.006902078166604042, 0.0022936470340937376, 0.002534396480768919, 0.008255180902779102, 0.050275787711143494, 0.010059978812932968, 0.002369373105466366, 0.1162492111325264, 0.004811800550669432, 0.0006524184136651456, 0.01903468370437622, 0.02954133413732052, 0.00046932054101489484, 0.00033492318470962346, 0.00034205769770778716, 0.0008737134630791843, 0.0010339225409552455, 0.13635912537574768, 0.0005708395619876683, 0.000555436359718442, 0.0006928035872988403, 0.004714876879006624, 0.21640180051326752, 0.0034742436837404966, 0.0008826258708722889, 0.0002362243685638532, 0.00025912519777193666, 0.0001832663983805105, 0.00020022602984681726, 0.0001550296728964895, 0.00011824213288491592, 0.00014876987552270293, 0.00014428103168029338, 0.0001512540184194222, 0.00015278479258995503, 0.00046820161514915526, 0.0032152871135622263]
train_acc: [0.06788793103448276, 0.13254310344827586, 0.22359913793103448, 0.30064655172413796, 0.42420977011494254, 0.5265804597701149, 0.6267959770114943, 0.6991738505747127, 0.7417385057471265, 0.7411997126436782, 0.8103448275862069, 0.8917025862068966, 0.869073275862069, 0.8997844827586207, 0.8927801724137931, 0.9207974137931034, 0.9299568965517241, 0.8335129310344828, 0.9385775862068966, 0.953125, 0.947198275862069, 0.9509698275862069, 0.9380387931034483, 0.9346264367816093, 0.9170258620689655, 0.959051724137931, 0.9655172413793104, 0.9703663793103449, 0.9369612068965517, 0.9719827586206896, 0.947198275862069, 0.9735991379310345, 0.9768318965517241, 0.9585129310344828, 0.9234913793103449, 0.9660560344827587, 0.9768318965517241, 0.9800646551724138, 0.9838362068965517, 0.978448275862069, 0.9849137931034483, 0.9644396551724138, 0.9595905172413793, 0.9795258620689655, 0.9806034482758621, 0.9768318965517241, 0.9676724137931034, 0.9294181034482759, 0.96875, 0.9865301724137931, 0.9913793103448276, 0.9892241379310345, 0.974676724137931, 0.9741379310344828, 0.9719827586206896, 0.9832974137931034, 0.9849137931034483, 0.9913793103448276, 0.9779094827586207, 0.990301724137931, 0.9870689655172413, 0.9876077586206896, 0.9466594827586207, 0.9240301724137931, 0.9886853448275862, 0.9773706896551724, 0.9849137931034483, 0.9854525862068966, 0.9854525862068966, 0.9854525862068966, 0.9827586206896551, 0.9676724137931034, 0.9908405172413793, 0.984375, 0.9789870689655172, 0.9865301724137931, 0.9962284482758621, 0.9849137931034483, 0.9897629310344828, 0.994073275862069, 0.965337643678161, 0.9849137931034483, 0.9919181034482759, 0.9881465517241379, 0.9644396551724138, 0.9335488505747127, 0.9525862068965517, 0.9913793103448276, 0.9924568965517241, 0.9951508620689655, 0.9989224137931034, 1.0, 0.9994612068965517, 0.9994612068965517, 1.0, 1.0, 1.0, 0.9967672413793104, 0.9827586206896551, 0.9908405172413793]
val_acc: [0.12731481481481483, 0.2023148148148148, 0.2377314814814815, 0.24814814814814815, 0.49421296296296297, 0.5766203703703704, 0.6965277777777777, 0.7780092592592592, 0.7935185185185186, 0.7925925925925926, 0.8497685185185185, 0.9092592592592593, 0.8770833333333333, 0.875925925925926, 0.8634259259259259, 0.90625, 0.8854166666666666, 0.93125, 0.9416666666666667, 0.95625, 0.9604166666666667, 0.9645833333333333, 0.9166666666666666, 0.7905092592592593, 0.9270833333333334, 0.8768518518518519, 0.9708333333333333, 0.9666666666666667, 0.9708333333333333, 0.8958333333333334, 0.9729166666666667, 0.9666666666666667, 0.9666666666666667, 0.9083333333333333, 0.9520833333333333, 0.9268518518518519, 0.9833333333333333, 0.9770833333333333, 0.975, 0.9833333333333333, 0.969675925925926, 0.9416666666666667, 0.9571759259259259, 0.9875, 0.9583333333333334, 0.95, 0.9351851851851852, 0.9416666666666667, 0.9854166666666667, 0.975925925925926, 0.9729166666666667, 0.9833333333333333, 0.9414351851851852, 0.975, 0.9520833333333333, 0.9854166666666667, 0.975925925925926, 0.96875, 0.9770833333333333, 0.9791666666666666, 0.9833333333333333, 0.9550925925925926, 0.93125, 0.9488425925925926, 0.98125, 0.9655092592592592, 0.98125, 0.9375, 0.98125, 0.9791666666666666, 0.9708333333333333, 0.9791666666666666, 0.9875, 0.98125, 0.9708333333333333, 0.9800925925925926, 0.9833333333333333, 0.9666666666666667, 0.9854166666666667, 0.9060185185185186, 0.9770833333333333, 0.9875, 0.9655092592592592, 0.9916666666666667, 0.9520833333333333, 0.9300925925925926, 0.9791666666666666, 0.9791666666666666, 0.9895833333333334, 0.9854166666666667, 0.9916666666666667, 0.9916666666666667, 0.9895833333333334, 0.9916666666666667, 0.9895833333333334, 0.9895833333333334, 0.9895833333333334, 0.9708333333333333, 0.982175925925926, 0.9895833333333334]


Test accuracy: 0.9805812757201645
